@*
    For more information on enabling MVC for empty projects, visit https://go.microsoft.com/fwlink/?LinkID=397860
*@
@{
}
<div class="terms">
   

        <p>This page contains Syllabus of Neural Networks of CSIT. </p>

        <div class="row no-gutters">

        </div>


        <div class="card col-xl-6 col-lg-6 col-md-6 col-sm-12">


            <div class="card-body p-0">
                <table class="table table-sm">

                    <tbody>
                        <tr>
                            <td>Title</td>

                            <td>
                                Neural Networks
                            </td>
                        </tr>
                        <tr>
                            <td>Course code</td>

                            <td>CSC372</td>
                        </tr>
                        <tr>
                            <td>Nature of course</td>

                            <td>Theory + Lab</td>
                        </tr>
                        <tr>
                            <td>Semester</td>

                            <td>Sixth-Semester</td>
                        </tr>
                        <tr>
                            <td>Full marks</td>

                            <td>60 + 20 + 20</td>
                        </tr>
                        <tr>
                            <td>Pass marks</td>

                            <td>24 + 8 + 8</td>
                        </tr>
                        <tr>
                            <td>Credit Hrs</td>

                            <td>3</td>
                        </tr>
                        <tr>
                            <td>Elective/Compulsary</td>

                            <td>Elective</td>

                        </tr>

                    </tbody>
                </table>
            </div>

        </div>



        <div class="row">
            <div class="col">
                <div class="card">
                    <div class="card-header">
                        <h3 class="card-title">
                            <i class="fa fa-book"></i>
                            Course Description
                        </h3>
                     
                    </div>
                    <!-- /.card-header -->
                    <div class="card-body">
                        <p><b>Course Description:</b></p><p>The course introduces the underlying principles and design of Neural Network. The course covers the basics concepts of Neural Network including: its architecture, learning processes, single layer and multilayer perceptron followed by Recurrent Neural Network</p><p><b>Course Objective:</b></p><p>The course objective is to demonstrate the concept of supervised learning, unsupervised learning in conjunction with different architectures of Neural Network</p>
                    </div>
                    <!-- /.card-body -->
                </div>
                <!-- /.card -->
            </div>
            <!-- ./col -->

        </div>

        <div class="row">
            <div class="col">
                <div class="card">
                    <div class="card-header">
                        <h3 class="card-title">
                            <i class="fa fa-file"></i>
                            Units and Unit Content
                        </h3>
                      
                    </div>
                    <!-- /.card-header -->
                    <div class="card-body">
                        <dl>

                            <dt>
                                1.
                                Introduction to Neural Network
                            </dt>
                            <dt>Teaching Hours: 4 hrs</dt>
                            <dd><p>Basics of neural networks and human brain, Models of a neuron, Neural Network viewed as Directed Graphs, Feedback, Network Architectures, Knowledge Representation, Learning Processes, Learning Tasks</p></dd>

                            <dt>
                                2.
                                Rosenblatt’s Perceptron
                            </dt>
                            <dt>Teaching Hours: 3 hrs</dt>
                            <dd><p>Introduction, Perceptron, The Perceptron Convergence Theorem, Relation between the Perceptron and Bayes Classifier for a Gaussian Environment, The Batch Perceptron Algorithm</p></dd>

                            <dt>
                                3.
                                Model Building through Regression
                            </dt>
                            <dt>Teaching Hours: 5 hrs</dt>
                            <dd><p>Introduction, Linear Regression Model: Preliminary Considerations, Maximum a Posteriori Estimation of the Parameter Vector, Relationship Between Regularized Least-Squares Estimation and Map Estimation, Computer Experiment: Pattern Classification, The Minimum-Description Length Principle, Finite Sample-Size Considerations, The instrumental- Variables Method</p></dd>

                            <dt>
                                4.
                                The Least-Mean-Square Algorithm
                            </dt>
                            <dt>Teaching Hours: 5 hrs</dt>
                            <dd><p>Introduction, Filtering Structure of the LMS Algorithm, Unconstrained Optimization: A Review, The Wiener Filter, The Least-Mean-Square Algorithm, Markov Model Portraying the Deviation of the LMS Algorithm from the Wiener Filter, The Langevin Equation: Characterization of Brownian Motion, Kushner‟s Direct-Averaging Method, Statistical LMS Learning Theory for Small Learning-Rate Parameter, Virtues and Limitations of the LMS Algorithm, Learning-Rate Annealing Schedules</p></dd>

                            <dt>
                                5.
                                Multilayer Perceptron
                            </dt>
                            <dt>Teaching Hours: 8 hrs</dt>
                            <dd><p>Introduction, Batch Learning and On-Line Learning, The Back-Propagation Algorithm, XOR problem, Heuristics for Making the back-propagation Algorithm Perform Better, Back Propagation and Differentiation, The Hessian and Its Role in On-Line Learning, Optimal Annealing and Adaptive Control of the Learning Rate, Generalization, Approximations of Functions, Cross Validation, Complexity Regularization and Network Pruning, Virtues and Limitations of Back-Propagation Learning, Supervised Learning Viewed as Optimization Problem, Convolutional Networks, Nonlinear Filtering, Small-Scale Versus Large-Scale Learning Problems</p></dd>

                            <dt>
                                6.
                                Kernel Methods and Radial-Basis Function Networks
                            </dt>
                            <dt>Teaching Hours: 7 hrs</dt>
                            <dd><p>Introduction, Cover‟s Theorem on the separability of Patterns, The Interpolation problem, Radial-Basis-Function Networks, K-Means Clustering, Recursive Least-Squares Estimation of the Weight Vector, Hybrid Learning Procedure for RBF Networks, Kernel Regression and Its Relation to RBF Networks</p></dd>

                            <dt>
                                7.
                                Self-Organizing Maps
                            </dt>
                            <dt>Teaching Hours: 6 hrs</dt>
                            <dd><p>Introduction, Two Basic Feature-Mapping Models, Self-Organizing Map, Properties of the Feature Map, Contextual Maps, Hierarchical Vector Quantization, Kernel Self-Organizing Map, Relationship between Kernel SOM and Kullback-Leibler Divergence</p></dd>

                            <dt>
                                8.
                                Dynamic Driven Recurrent Networks
                            </dt>
                            <dt>Teaching Hours: 7 hrs</dt>
                            <dd><p>Introduction, Recurrent Network Architectures, Universal Approximation Theorem, Controllability and Observability, Computational Power of Recurrent Networks, Learning Algorithms, Back Propagation through Time, Real-Time Recurrent Learning, Vanishing Gradients in Recurrent Networks, Supervised Training Framework for Recurrent Networks Using Non Sate Estimators, Adaptivity Considerations, Case Study: Model Reference Applied to Neurocontrol</p></dd>

                        </dl>
                    </div>
                    <!-- /.card-body -->
                </div>
                <!-- /.card -->
            </div>
            <!-- ./col -->

        </div>

        <div class="row">
            <div class="col">
                <div class="card">
                    <div class="card-header">
                        <h3 class="card-title">
                            <i class="fa fa-desktop"></i>
                            <i class="fa fa-flask"></i>
                            Lab and Practical works
                        </h3>
                      
                    </div>
                    <!-- /.card-header -->
                    <div class="card-body">
                        <p><b>Laboratory works:</b></p><p>Practical should be focused on Single Layer Perceptron, Multilayer Perceptron, Supervised Learning, Unsupervised Learning, Recurrent Neural Network, Linear Prediction and Pattern Classification</p>
                    </div>
                    <!-- /.card-body -->
                </div>
                <!-- /.card -->
            </div>
            <!-- ./col -->

        </div>



    </div>
